{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thedronemenace/media-tools/blob/main/Clip_Factory_Bot_Autopilot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d75edec",
      "metadata": {
        "id": "2d75edec"
      },
      "source": [
        "# 🔥 Clip Factory Bot — Autopilot (TikTok + Instagram)\n",
        "**What this notebook does (hands‑free content factory):**\n",
        "1. Mounts your Google Drive\n",
        "2. Pulls safe trending sources (podcasts, interviews, speeches) via `yt-dlp`\n",
        "3. Auto-cuts **10 clips/day** (default) into **20–30s vertical (9:16)** videos\n",
        "4. Generates **subtitles** with Whisper and **burns them** into each clip\n",
        "5. Adds your **watermark** (e.g., `@thedronemenace`)\n",
        "6. Auto-writes a caption + **rotating hashtags** (5 for TikTok, 20+ for Instagram) into a `.txt` next to each video\n",
        "7. Saves everything to your Drive folder: **`Autopost_Clips`**\n",
        "\n",
        "> Once you connect this Drive folder to your scheduler/emulator workflow, your posts can go out automatically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "2c1b0828",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c1b0828",
        "outputId": "8e80e424-3d43-4c9c-cdab-b3294c896966"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "✅ Dependencies installed.\n"
          ]
        }
      ],
      "source": [
        "# @title STEP 0 — Install dependencies (5–7 min on first run)\n",
        "# This cell installs: ffmpeg, yt-dlp, OpenAI Whisper (for subtitles)\n",
        "\n",
        "!apt-get -y update >/dev/null\n",
        "!apt-get -y install ffmpeg >/dev/null\n",
        "\n",
        "!pip -q install yt-dlp ffmpeg-python openai-whisper numpy pandas >/dev/null\n",
        "\n",
        "print(\"✅ Dependencies installed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "46fb4df4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46fb4df4",
        "outputId": "f0062b25-e333-4383-d3b1-0139d35f055d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "✅ Drive mounted. You will see 'drive/MyDrive' available.\n"
          ]
        }
      ],
      "source": [
        "# @title STEP 1 — Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print(\"✅ Drive mounted. You will see 'drive/MyDrive' available.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "3b003bf8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3b003bf8",
        "outputId": "322d7575-e027-41e5-9423-7083513e7742"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Config set: 10 clips/run → Drive/Autopost_Clips | Watermark: @thedronemenace\n"
          ]
        }
      ],
      "source": [
        "# @title STEP 2 — Configure your bot (edit the fields then run)\n",
        "HANDLE = \"@thedronemenace\"  # @title Your watermark handle (e.g., @thedronemenace)\n",
        "OUTPUT_DIR = \"Autopost_Clips\"  # @title Drive folder to save clips to\n",
        "CLIPS_PER_DAY = 10  # @title How many clips to produce per run (recommended: 10)\n",
        "MIN_CLIP_SEC = 20   # @title Min clip length (seconds)\n",
        "MAX_CLIP_SEC = 30   # @title Max clip length (seconds)\n",
        "\n",
        "# Safe viral-ish sources (podcast/interview/news channels).\n",
        "# You can add/remove links. The bot will pull the latest videos from these.\n",
        "SAFE_SOURCES = [\n",
        "  \"https://www.youtube.com/@PowerfulJRE/videos\",\n",
        "  \"https://www.youtube.com/@lexfridman/videos\",\n",
        "  \"https://www.youtube.com/@TED/videos\",\n",
        "  \"https://www.youtube.com/@valutainment/videos\",\n",
        "  \"https://www.youtube.com/@impacttheory/videos\",\n",
        "  \"https://www.youtube.com/@PBDPodcast/videos\",\n",
        "  \"https://www.youtube.com/@theDiaryOfACEO/videos\"\n",
        "]\n",
        "\n",
        "print(f\"✅ Config set: {CLIPS_PER_DAY} clips/run → Drive/{OUTPUT_DIR} | Watermark: {HANDLE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "9c0070c0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c0070c0",
        "outputId": "bffb0ebf-17da-4682-c1ca-8e4f4f71e07e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Folders ready:\n",
            "RAW  → /content/work/raw\n",
            "CUT  → /content/work/cut\n",
            "SUBS → /content/work/subs\n",
            "OUT  → /content/drive/MyDrive/Autopost_Clips\n"
          ]
        }
      ],
      "source": [
        "# @title STEP 3 — Prepare workspace folders\n",
        "import os\n",
        "\n",
        "WORK_DIR = \"/content/work\"\n",
        "RAW_DIR = os.path.join(WORK_DIR, \"raw\")\n",
        "CUT_DIR = os.path.join(WORK_DIR, \"cut\")\n",
        "SUB_DIR = os.path.join(WORK_DIR, \"subs\")\n",
        "OUT_DIR = \"/content/drive/MyDrive/\" + OUTPUT_DIR\n",
        "\n",
        "for d in (WORK_DIR, RAW_DIR, CUT_DIR, SUB_DIR, OUT_DIR):\n",
        "    os.makedirs(d, exist_ok=True)\n",
        "\n",
        "print(\"✅ Folders ready:\")\n",
        "print(\"RAW  →\", RAW_DIR)\n",
        "print(\"CUT  →\", CUT_DIR)\n",
        "print(\"SUBS →\", SUB_DIR)\n",
        "print(\"OUT  →\", OUT_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "0c9bd1c9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c9bd1c9",
        "outputId": "b9755ac9-0a9d-4976-8cc9-105f12f58530"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "→ Grabbing: https://www.youtube.com/@PowerfulJRE/videos\n",
            "→ Grabbing: https://www.youtube.com/@lexfridman/videos\n",
            "→ Grabbing: https://www.youtube.com/@TED/videos\n",
            "→ Grabbing: https://www.youtube.com/@valutainment/videos\n",
            "→ Grabbing: https://www.youtube.com/@impacttheory/videos\n",
            "→ Grabbing: https://www.youtube.com/@PBDPodcast/videos\n",
            "→ Grabbing: https://www.youtube.com/@theDiaryOfACEO/videos\n",
            "✅ Downloaded raw videos: 12\n"
          ]
        }
      ],
      "source": [
        "# @title STEP 4 — Fetch latest videos from safe sources (yt-dlp)\n",
        "import os, subprocess\n",
        "from glob import glob\n",
        "\n",
        "MAX_VIDS_PER_SOURCE = 3  # up to 3 per source\n",
        "\n",
        "def download_from_source(url):\n",
        "    cmd = [\n",
        "        \"yt-dlp\",\n",
        "        \"--no-warnings\",\n",
        "        \"--ignore-errors\",\n",
        "        \"--dateafter\", \"now-1month\",\n",
        "        \"-f\", \"bv*[ext=mp4]+ba[ext=m4a]/b[ext=mp4]/b\",\n",
        "        \"-o\", os.path.join(RAW_DIR, \"%(uploader)s__%(title).80B__%(id)s.%(ext)s\"),\n",
        "        \"--max-downloads\", str(MAX_VIDS_PER_SOURCE),\n",
        "        url\n",
        "    ]\n",
        "    print(\"→ Grabbing:\", url)\n",
        "    subprocess.run(cmd, check=False)\n",
        "\n",
        "for src in SAFE_SOURCES:\n",
        "    try:\n",
        "        download_from_source(src)\n",
        "    except Exception as e:\n",
        "        print(\"Failed:\", src, e)\n",
        "\n",
        "raw_files = sorted(glob(os.path.join(RAW_DIR, \"*.mp4\")))\n",
        "print(f\"✅ Downloaded raw videos: {len(raw_files)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a38db6ef",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a38db6ef",
        "outputId": "254eea9b-5c25-46a3-a877-908b24437b3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2134291766.py:34: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  ts = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
            "100%|███████████████████████████████████████| 461M/461M [00:14<00:00, 34.1MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Created: /content/drive/MyDrive/Autopost_Clips/The Diary Of A CEO__World No.1 Fasting Expert： The Link Between Cancer & Fasting That They're Hiding__jDG1m_b5Ih0__20250902_174725__9x16_thedronemenace.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2134291766.py:34: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  ts = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Created: /content/drive/MyDrive/Autopost_Clips/PBD Podcast__Benjamin Netanyahu ADMITS Genocide, Slams AIPAC Critics & Trump Owning Gaza ｜ PB__0nsgCE4HC0U__20250902_175247__9x16_thedronemenace.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2134291766.py:34: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  ts = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n"
          ]
        }
      ],
      "source": [
        "# @title STEP 5 — Cut 20–30s vertical segments and generate subtitles\n",
        "import os, subprocess, random, json\n",
        "from glob import glob\n",
        "from datetime import datetime\n",
        "\n",
        "def get_duration(path):\n",
        "    cmd = [\n",
        "        \"ffprobe\", \"-v\", \"error\", \"-print_format\", \"json\", \"-show_format\", \"-show_streams\", path\n",
        "    ]\n",
        "    out = subprocess.check_output(cmd).decode(\"utf-8\", \"ignore\")\n",
        "    info = json.loads(out)\n",
        "    dur = float(info[\"format\"][\"duration\"])\n",
        "    return dur\n",
        "\n",
        "def pick_segment(duration, min_sec, max_sec):\n",
        "    length = random.randint(min_sec, max_sec)\n",
        "    if duration <= length + 2:\n",
        "        return 0, min(duration-1, length)\n",
        "    import random as _r\n",
        "    start = _r.uniform(0, max(0, duration - length - 1))\n",
        "    return start, length\n",
        "\n",
        "made = 0\n",
        "random.shuffle(raw_files)\n",
        "\n",
        "for src in raw_files:\n",
        "    if made >= CLIPS_PER_DAY:\n",
        "        break\n",
        "    try:\n",
        "        dur = get_duration(src)\n",
        "        ss, ll = pick_segment(dur, MIN_CLIP_SEC, MAX_CLIP_SEC)\n",
        "\n",
        "        base = os.path.splitext(os.path.basename(src))[0]\n",
        "        ts = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        cut_path = os.path.join(\"/content/work/cut\", f\"{base}__{ts}.mp4\")\n",
        "\n",
        "        # 1) Cut a 20-30s chunk\n",
        "        subprocess.run([\n",
        "            \"ffmpeg\", \"-y\",\n",
        "            \"-ss\", str(ss), \"-t\", str(ll),\n",
        "            \"-i\", src,\n",
        "            \"-c:v\", \"libx264\", \"-c:a\", \"aac\",\n",
        "            \"-movflags\", \"+faststart\",\n",
        "            cut_path\n",
        "        ], check=False, stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT)\n",
        "\n",
        "        # 2) Generate subtitles with Whisper\n",
        "        import whisper\n",
        "        model = whisper.load_model(\"small\")\n",
        "        result = model.transcribe(cut_path, fp16=False, language='en')\n",
        "\n",
        "        # Write SRT\n",
        "        try:\n",
        "            import srt\n",
        "        except:\n",
        "            !pip -q install srt >/dev/null\n",
        "            import srt\n",
        "        import datetime as dt\n",
        "        subs = []\n",
        "        for i, seg in enumerate(result.get(\"segments\", [])):\n",
        "            start = dt.timedelta(seconds=max(seg.get(\"start\", 0), 0))\n",
        "            end = dt.timedelta(seconds=max(seg.get(\"end\", 0), 0))\n",
        "            subs.append(srt.Subtitle(index=i+1, start=start, end=end, content=str(seg.get(\"text\", \"\")).strip()))\n",
        "        srt_path = os.path.join(\"/content/work/subs\", os.path.splitext(os.path.basename(cut_path))[0] + \".srt\")\n",
        "        with open(srt_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(srt.compose(subs))\n",
        "\n",
        "        # 3) Make vertical 9:16, burn subs, add watermark\n",
        "        out_name = os.path.basename(cut_path).replace(\".mp4\", \"__9x16_\" + HANDLE[1:] + \".mp4\")\n",
        "        out_path = os.path.join(\"/content/drive/MyDrive/\" + OUTPUT_DIR, out_name)\n",
        "\n",
        "        vf = (\n",
        "            \"scale=-2:1920:flags=lanczos,\"\n",
        "            \"crop=1080:1920,\"\n",
        "            \"subtitles='\" + srt_path.replace(\"'\", \"\\\\'\") + \"':force_style='Fontsize=24,Outline=2,Shadow=1',\"\n",
        "            \"drawtext=fontfile=/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf:\"\n",
        "            \"text='\" + HANDLE.replace(\":\", \"\\\\:\") + \"':x=(w-tw-40):y=(h-th-40):fontsize=28:box=1:boxcolor=black@0.4:boxborderw=10\"\n",
        "        )\n",
        "\n",
        "        subprocess.run([\n",
        "            \"ffmpeg\", \"-y\", \"-i\", cut_path,\n",
        "            \"-vf\", vf,\n",
        "            \"-c:v\", \"libx264\", \"-preset\", \"veryfast\", \"-crf\", \"23\",\n",
        "            \"-c:a\", \"aac\", \"-b:a\", \"128k\",\n",
        "            \"-movflags\", \"+faststart\",\n",
        "            out_path\n",
        "        ], check=False, stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT)\n",
        "\n",
        "        print(\"✅ Created:\", out_path)\n",
        "        made += 1\n",
        "    except Exception as e:\n",
        "        print(\"Skip due to error:\", e)\n",
        "        continue\n",
        "\n",
        "print(f\"✅ Finished: {made} vertical clips saved to Drive/{OUTPUT_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70efc8e0",
      "metadata": {
        "id": "70efc8e0"
      },
      "outputs": [],
      "source": [
        "# @title STEP 6 — Auto-captions + rotating hashtags (creates .txt next to each video)\n",
        "import os, re, random\n",
        "from glob import glob\n",
        "OUT_DIR = \"/content/drive/MyDrive/\" + OUTPUT_DIR\n",
        "\n",
        "HASHTAGS_TT_BUCKETS = [\n",
        "    [\"#fyp\", \"#viral\", \"#trending\", \"#xyzbca\", \"#foryou\"],\n",
        "    [\"#viralvideo\", \"#reels\", \"#tiktok\", \"#explore\", \"#mustwatch\"],\n",
        "    [\"#motivation\", \"#podcast\", \"#interview\", \"#mindset\", \"#success\"],\n",
        "    [\"#wow\", \"#shocking\", \"#insane\", \"#waitforit\", \"#watchtillend\"],\n",
        "]\n",
        "\n",
        "HASHTAGS_IG = [\n",
        "    \"#reels\", \"#reelsinstagram\", \"#reelitfeelit\", \"#explorepage\", \"#viral\",\n",
        "    \"#trending\", \"#instadaily\", \"#discover\", \"#motivation\", \"#mindset\",\n",
        "    \"#inspiration\", \"#podcast\", \"#interview\", \"#clips\", \"#dailyreels\",\n",
        "    \"#mustwatch\", \"#foryou\", \"#wow\", \"#insane\", \"#watchtillend\"\n",
        "]\n",
        "\n",
        "def slugify(t):\n",
        "    t = re.sub(r\"[^\\w\\s-]\", \"\", t)\n",
        "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
        "    return t\n",
        "\n",
        "mp4s = sorted(glob(os.path.join(OUT_DIR, \"*.mp4\")))\n",
        "for vid in mp4s:\n",
        "    base = os.path.splitext(os.path.basename(vid))[0]\n",
        "    txt_path = os.path.join(OUT_DIR, base + \".txt\")\n",
        "\n",
        "    # simple caption from filename\n",
        "    cap_core = slugify(base.split(\"__\")[0]).replace(\"_\", \" \")\n",
        "    hook = random.choice([\n",
        "        \"Wait for it…\", \"You won’t believe this.\", \"This changed my mind.\",\n",
        "        \"Unreal moment.\", \"What do you think?\"\n",
        "    ])\n",
        "    tt_tags = random.choice(HASHTAGS_TT_BUCKETS)\n",
        "    ig_tags = HASHTAGS_IG\n",
        "\n",
        "    caption = hook + \"\\n\\n\" + HANDLE + \"\\n\\n\" + \\\n",
        "              \"TikTok: \" + \" \".join(tt_tags) + \"\\n\" + \\\n",
        "              \"Instagram: \" + \" \".join(ig_tags)\n",
        "\n",
        "    with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(caption)\n",
        "\n",
        "print(\"✅ Captions written for\", len(mp4s), \"videos. (.txt files next to each .mp4)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83cd6842",
      "metadata": {
        "id": "83cd6842"
      },
      "source": [
        "## ✅ Done\n",
        "- Your clips are in **`Drive/MyDrive/Autopost_Clips`** with matching `.txt` captions.\n",
        "- Pair this with your **emulator bot** (Bluestacks macro) to auto-post on schedule.\n",
        "\n",
        "### Notes\n",
        "- First run can take longer while Whisper downloads a model.\n",
        "- You can switch `model = whisper.load_model(\"small\")` to `'tiny'` for faster (lower quality) or `'medium'/'large'` for higher quality.\n",
        "- Add/remove `SAFE_SOURCES` to tune the niche.\n",
        "- To run daily on autopilot: Use Colab’s “Schedule cell execution” or a simple desktop automation to open Colab and click *Run all* each day."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}