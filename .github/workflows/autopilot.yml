name: MediaTools Autopilot

on:
  workflow_dispatch:
  schedule:
    - cron: "0 */2 * * *"   # every 2 hours

jobs:
  run-autopilot:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"

      - name: Install system + Python deps
        run: |
          sudo apt-get update -y
          sudo apt-get install -y ffmpeg
          python -m pip install --upgrade pip
          pip install jupyter nbconvert ipykernel \
                     yt-dlp ffmpeg-python openai-whisper srt pandas pyyaml \
                     pydrive2

      - name: Convert notebook to script
        run: |
          jupyter nbconvert --to script MediaTools_Autopilot.ipynb

      - name: Patch script for GitHub runner
        run: |
          python3 - <<'PY'
          import re, io, os
          src = "MediaTools_Autopilot.py"
          with io.open(src, "r", encoding="utf-8") as f:
              s = f.read()

          # Remove Colab-specific lines
          s = s.replace("from google.colab import drive", "print('Skipping Colab import')")
          s = re.sub(r"drive\.mount\(.*\)", "print('Drive mount skipped')", s)

          # Rewrite paths
          s = s.replace("/content/drive/MyDrive", "workspace")
          s = s.replace("/content", "workspace")

          with io.open(src, "w", encoding="utf-8") as f:
              f.write(s)

          os.makedirs("workspace", exist_ok=True)
          os.makedirs("workspace/Autopost_Clips", exist_ok=True)
          PY

      - name: Run script
        run: |
          python MediaTools_Autopilot.py

      - name: Upload results to Google Drive
        env:
          GDRIVE_KEY: ${{ secrets.GDRIVE_KEY }}
          FOLDER_ID:  ${{ secrets.FOLDER_ID }}
        run: |
          echo "$GDRIVE_KEY" > sa.json
          python3 - <<'PY'
          import os, glob, zipfile
          from pydrive2.auth import GoogleAuth
          from pydrive2.drive import GoogleDrive

          gauth = GoogleAuth()
          gauth.settings['client_config_backend'] = 'service'
          gauth.settings['service_config'] = {'client_json_file_path': "sa.json"}
          gauth.ServiceAuth()
          drive = GoogleDrive(gauth)

          folder_id = os.environ["FOLDER_ID"]
          files = []
          for pat in ["workspace/**/*.mp4", "workspace/**/*.txt", "*.ipynb"]:
              files.extend(glob.glob(pat, recursive=True))

          for fp in files:
            title = os.path.basename(fp)
            f = drive.CreateFile({"title": title, "parents": [{"id": folder_id}]})
            f.SetContentFile(fp)
            f.Upload()
            print("✅ Uploaded:", title)

          zip_name = "autopost_run.zip"
          with zipfile.ZipFile(zip_name, "w") as z:
            for fp in files:
              z.write(fp)
          fz = drive.CreateFile({"title": zip_name, "parents": [{"id": folder_id}]})
          fz.SetContentFile(zip_name)
          fz.Upload()
          print("✅ Uploaded archive:", zip_name)
          PY

      - name: Upload artifacts (fallback)
        uses: actions/upload-artifact@v4
        with:
          name: autopilot-output
          path: |
            workspace/**
            *.ipynb
          if-no-files-found: warn
          retention-days: 7

      - name: Clean up old logs (keep last 20)
        uses: dev-drprasad/delete-older-releases@v0.2.1
        with:
          keep_latest: 20
          delete_tags: true
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
